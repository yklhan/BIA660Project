{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import lda\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(file_name):\n",
    "    with open(file_name, 'r') as reader:\n",
    "        line_list = reader.readlines()\n",
    "    line_list = [x.strip() for x in line_list]\n",
    "    return line_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pros =read_from_file('project_pro.txt')\n",
    "cons = read_from_file('project_con.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chooseTopk(data_list, topic_num, top_words_num, top_topics_num, k_user):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 100\n",
      "INFO:lda:vocab_size: 153\n",
      "INFO:lda:n_words: 679\n",
      "INFO:lda:n_topics: 5\n",
      "INFO:lda:n_iter: 500\n",
      "D:\\miniconda\\envs\\tf\\lib\\site-packages\\lda\\utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -5953\n",
      "INFO:lda:<10> log likelihood: -4067\n",
      "INFO:lda:<20> log likelihood: -3922\n",
      "INFO:lda:<30> log likelihood: -3889\n",
      "INFO:lda:<40> log likelihood: -3859\n",
      "INFO:lda:<50> log likelihood: -3865\n",
      "INFO:lda:<60> log likelihood: -3857\n",
      "INFO:lda:<70> log likelihood: -3837\n",
      "INFO:lda:<80> log likelihood: -3811\n",
      "INFO:lda:<90> log likelihood: -3792\n",
      "INFO:lda:<100> log likelihood: -3803\n",
      "INFO:lda:<110> log likelihood: -3840\n",
      "INFO:lda:<120> log likelihood: -3780\n",
      "INFO:lda:<130> log likelihood: -3788\n",
      "INFO:lda:<140> log likelihood: -3783\n",
      "INFO:lda:<150> log likelihood: -3777\n",
      "INFO:lda:<160> log likelihood: -3747\n",
      "INFO:lda:<170> log likelihood: -3785\n",
      "INFO:lda:<180> log likelihood: -3764\n",
      "INFO:lda:<190> log likelihood: -3761\n",
      "INFO:lda:<200> log likelihood: -3797\n",
      "INFO:lda:<210> log likelihood: -3789\n",
      "INFO:lda:<220> log likelihood: -3759\n",
      "INFO:lda:<230> log likelihood: -3787\n",
      "INFO:lda:<240> log likelihood: -3791\n",
      "INFO:lda:<250> log likelihood: -3763\n",
      "INFO:lda:<260> log likelihood: -3787\n",
      "INFO:lda:<270> log likelihood: -3764\n",
      "INFO:lda:<280> log likelihood: -3743\n",
      "INFO:lda:<290> log likelihood: -3752\n",
      "INFO:lda:<300> log likelihood: -3764\n",
      "INFO:lda:<310> log likelihood: -3765\n",
      "INFO:lda:<320> log likelihood: -3760\n",
      "INFO:lda:<330> log likelihood: -3778\n",
      "INFO:lda:<340> log likelihood: -3750\n",
      "INFO:lda:<350> log likelihood: -3792\n",
      "INFO:lda:<360> log likelihood: -3765\n",
      "INFO:lda:<370> log likelihood: -3741\n",
      "INFO:lda:<380> log likelihood: -3762\n",
      "INFO:lda:<390> log likelihood: -3759\n",
      "INFO:lda:<400> log likelihood: -3806\n",
      "INFO:lda:<410> log likelihood: -3776\n",
      "INFO:lda:<420> log likelihood: -3783\n",
      "INFO:lda:<430> log likelihood: -3730\n",
      "INFO:lda:<440> log likelihood: -3764\n",
      "INFO:lda:<450> log likelihood: -3775\n",
      "INFO:lda:<460> log likelihood: -3776\n",
      "INFO:lda:<470> log likelihood: -3757\n",
      "INFO:lda:<480> log likelihood: -3775\n",
      "INFO:lda:<490> log likelihood: -3745\n",
      "INFO:lda:<499> log likelihood: -3762\n",
      "INFO:lda:n_documents: 100\n",
      "INFO:lda:vocab_size: 129\n",
      "INFO:lda:n_words: 657\n",
      "INFO:lda:n_topics: 5\n",
      "INFO:lda:n_iter: 500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "D:\\miniconda\\envs\\tf\\lib\\site-packages\\lda\\utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -5215\n",
      "INFO:lda:<10> log likelihood: -3426\n",
      "INFO:lda:<20> log likelihood: -3293\n",
      "INFO:lda:<30> log likelihood: -3310\n",
      "INFO:lda:<40> log likelihood: -3254\n",
      "INFO:lda:<50> log likelihood: -3275\n",
      "INFO:lda:<60> log likelihood: -3251\n",
      "INFO:lda:<70> log likelihood: -3253\n",
      "INFO:lda:<80> log likelihood: -3232\n",
      "INFO:lda:<90> log likelihood: -3263\n",
      "INFO:lda:<100> log likelihood: -3251\n",
      "INFO:lda:<110> log likelihood: -3267\n",
      "INFO:lda:<120> log likelihood: -3255\n",
      "INFO:lda:<130> log likelihood: -3240\n",
      "INFO:lda:<140> log likelihood: -3244\n",
      "INFO:lda:<150> log likelihood: -3265\n",
      "INFO:lda:<160> log likelihood: -3203\n",
      "INFO:lda:<170> log likelihood: -3262\n",
      "INFO:lda:<180> log likelihood: -3280\n",
      "INFO:lda:<190> log likelihood: -3282\n",
      "INFO:lda:<200> log likelihood: -3258\n",
      "INFO:lda:<210> log likelihood: -3273\n",
      "INFO:lda:<220> log likelihood: -3266\n",
      "INFO:lda:<230> log likelihood: -3239\n",
      "INFO:lda:<240> log likelihood: -3221\n",
      "INFO:lda:<250> log likelihood: -3265\n",
      "INFO:lda:<260> log likelihood: -3254\n",
      "INFO:lda:<270> log likelihood: -3253\n",
      "INFO:lda:<280> log likelihood: -3212\n",
      "INFO:lda:<290> log likelihood: -3223\n",
      "INFO:lda:<300> log likelihood: -3218\n",
      "INFO:lda:<310> log likelihood: -3216\n",
      "INFO:lda:<320> log likelihood: -3204\n",
      "INFO:lda:<330> log likelihood: -3228\n",
      "INFO:lda:<340> log likelihood: -3223\n",
      "INFO:lda:<350> log likelihood: -3219\n",
      "INFO:lda:<360> log likelihood: -3251\n",
      "INFO:lda:<370> log likelihood: -3236\n",
      "INFO:lda:<380> log likelihood: -3239\n",
      "INFO:lda:<390> log likelihood: -3208\n",
      "INFO:lda:<400> log likelihood: -3237\n",
      "INFO:lda:<410> log likelihood: -3256\n",
      "INFO:lda:<420> log likelihood: -3244\n",
      "INFO:lda:<430> log likelihood: -3274\n",
      "INFO:lda:<440> log likelihood: -3239\n",
      "INFO:lda:<450> log likelihood: -3291\n",
      "INFO:lda:<460> log likelihood: -3256\n",
      "INFO:lda:<470> log likelihood: -3231\n",
      "INFO:lda:<480> log likelihood: -3210\n",
      "INFO:lda:<490> log likelihood: -3214\n",
      "INFO:lda:<499> log likelihood: -3201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x2d38db16f08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre-decided by the requirement of LDA algorithm\n",
    "topic_num=5\n",
    "\n",
    "#tokenization\n",
    "pros_tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "cons_tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')                               \n",
    "\n",
    "#transform the docs into a count matrix\n",
    "#get the vocabulary\n",
    "pros_matrix = pros_tf_vectorizer.fit_transform(pros)\n",
    "pros_vocab = pros_tf_vectorizer.get_feature_names()\n",
    "\n",
    "cons_matrix = cons_tf_vectorizer.fit_transform(cons)\n",
    "cons_vocab = cons_tf_vectorizer.get_feature_names()\n",
    "\n",
    "#initialize the LDA model\n",
    "pro_model = lda.LDA(n_topics=topic_num, n_iter=500)\n",
    "con_model = lda.LDA(n_topics=topic_num, n_iter=500)\n",
    "\n",
    "#fit the model to the dataset\n",
    "pro_model.fit(pros_matrix)\n",
    "con_model.fit(cons_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process pros\n",
    "topic_keywords = {}\n",
    "#write the top terms for each topic\n",
    "#ancillary\n",
    "top_words_num=3\n",
    "pro_topic_mixes= pro_model.topic_word_\n",
    "fw=open('pro_top_terms_per_topic.txt','w')\n",
    "for i in range(topic_num):#for each topic\n",
    "    top_indexes=np.argsort(pro_topic_mixes[i])[::-1][:top_words_num]                              \n",
    "    my_top=''\n",
    "    for ind in top_indexes:\n",
    "        my_top+=pros_vocab[ind]+' '\n",
    "        if i in topic_keywords:\n",
    "            topic_keywords[i].append(pros_vocab[ind])\n",
    "        else:\n",
    "            topic_keywords[i] = [pros_vocab[ind]]\n",
    "    fw.write('TOPIC: '+str(i)+' --> '+str(my_top)+'\\n')\n",
    "fw.close()\n",
    "\n",
    "doc_topic = {}\n",
    "doc_top_topic = {}\n",
    "\n",
    "#write the top topics for each doc\n",
    "top_topics_num=3\n",
    "pro_doc_mixes= pro_model.doc_topic_\n",
    "fw=open('pro_topic_mixture_per_doc.txt','w')\n",
    "for i in range(len(pro_doc_mixes)):#for each doc\n",
    "    top_indexes=np.argsort(pro_doc_mixes[i])[::-1][:top_topics_num]     \n",
    "    my_top=''\n",
    "    for ind in top_indexes:\n",
    "        temp_topic = ind\n",
    "        temp_likelihood = round(pro_doc_mixes[i][ind], 2)\n",
    "        likelihood_top = -1\n",
    "        topic_top = -1\n",
    "        if temp_likelihood > likelihood_top:\n",
    "            likelihood_top = temp_likelihood\n",
    "            topic_top = temp_topic\n",
    "        my_top+=' '+str(ind)+':'+str(round(pro_doc_mixes[i][ind],2))\n",
    "        if i in doc_topic:\n",
    "            doc_topic[i].append((ind, round(pro_doc_mixes[i][ind], 2)))\n",
    "        else:\n",
    "            doc_topic[i] = [(ind, round(pro_doc_mixes[i][ind], 2))]\n",
    "    doc_top_topic[i] = topic_top\n",
    "    fw.write('DOC: '+str(i)+' --> '+str(my_top)+'\\n')\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP  1  pro comments' keywords are  ['amazon', 'day', 'people']\n",
      "e.g.  I love Amazon because of the opportunities they provide and the experience you can gain. I do believe management and communication can be more effective and everything will run much smoother day in and day out.\n",
      "e.g.  I love Amazon because of the opportunities they provide and the experience you can gain. I do believe management and communication can be more effective and everything will run much smoother day in and day out.\n",
      "e.g.  You do not need to have experience to start working there\n",
      "TOP  2  pro comments' keywords are  ['work', 'place', 'great']\n",
      "e.g.  A great place to work\n",
      "e.g.  Inspiring story place to be part of\n",
      "e.g.  Leadership principles are amazing, and they are used by everyone.\n",
      "e.g.  Great opportunities to advance laterally or vertically.\n",
      "e.g.  Great cultural foundation with Leadership Principals Rewarding challenges in work Seeing tangible outcome of work\n",
      "e.g.  Great benefits. I enjoy my work station\n",
      "e.g.  Work from home No commute\n"
     ]
    }
   ],
   "source": [
    "#print out the top k pros\n",
    "k_user = 2 #user parameter !!! can not be larger than topic_num\n",
    "\n",
    "invers_count = {}\n",
    "for key, value in doc_top_topic.items():\n",
    "    if value in invers_count:\n",
    "        invers_count[value] += 1\n",
    "    else:\n",
    "        invers_count[value] = 1\n",
    "\n",
    "count_dic = {}\n",
    "for k,v in invers_count.items():\n",
    "    count_dic[v] = k\n",
    "\n",
    "for i in range(k_user):    \n",
    "    l = len(count_dic.keys())\n",
    "    i_topicNum = count_dic[sorted(count_dic.keys())[l-i-1]]                \n",
    "    print(\"TOP \", i+1, \" pro comments' keywords are \", topic_keywords[i_topicNum])\n",
    "    \n",
    "    for docj, portion in doc_topic.items():\n",
    "        for j, posb in portion:\n",
    "            if j == i_topicNum and posb > 0.8:\n",
    "                print(\"e.g. \", pros[docj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP  1  con comments' keywords are  ['work', 'hard', 'fast']\n",
      "e.g.  no cons they are a great place to work\n",
      "e.g.  Work life balance is hard to have\n",
      "e.g.  Work life balance is tricky here\n",
      "e.g.  I liked working at Souq that years.\n",
      "e.g.  hard working environment - some teams are not colloborative\n",
      "e.g.  Lots of extra processes involved for product to reach the customers\n",
      "e.g.  Monotonous work, constantly standing, impersonal environment\n",
      "TOP  2  con comments' keywords are  ['company', 'bad', 'management']\n",
      "e.g.  big company so things can get lost\n",
      "e.g.  Ensuring we utilize Frugality as one of our Leadership Principles more effectively, what we lack in.\n",
      "e.g.  Large company with some evidence of bureaucracy building.\n",
      "e.g.  It can get repetitive but itâ€™s really not that bad\n",
      "e.g.  Frugality as a leadership principle can be good and bad compared to benefits at other FAANG companies. Stock vesting schedule.\n",
      "e.g.  Hight rollover rate. Constant change in management\n",
      "e.g.  large company that doesn't care all that much\n",
      "e.g.  Company is too big to move\n",
      "e.g.  Best job ever for sure\n"
     ]
    }
   ],
   "source": [
    "#process cons\n",
    "topic_keywords = {}\n",
    "#write the top terms for each topic\n",
    "#ancillary\n",
    "top_words_num=3\n",
    "con_topic_mixes= con_model.topic_word_\n",
    "fw=open('con_top_terms_per_topic.txt','w')\n",
    "for i in range(topic_num):#for each topic\n",
    "    top_indexes=np.argsort(con_topic_mixes[i])[::-1][:top_words_num]                              \n",
    "    my_top=''\n",
    "    for ind in top_indexes:\n",
    "        my_top+=cons_vocab[ind]+' '\n",
    "        if i in topic_keywords:\n",
    "            topic_keywords[i].append(cons_vocab[ind])\n",
    "        else:\n",
    "            topic_keywords[i] = [cons_vocab[ind]]\n",
    "    fw.write('TOPIC: '+str(i)+' --> '+str(my_top)+'\\n')\n",
    "fw.close()\n",
    "\n",
    "doc_topic = {}\n",
    "doc_top_topic = {}\n",
    "#write the top topics for each doc\n",
    "top_topics_num=3\n",
    "con_doc_mixes= con_model.doc_topic_\n",
    "fw=open('con_topic_mixture_per_doc.txt','w')\n",
    "for i in range(len(con_doc_mixes)):#for each doc\n",
    "    top_indexes=np.argsort(con_doc_mixes[i])[::-1][:top_topics_num]     \n",
    "    my_top=''\n",
    "    for ind in top_indexes:\n",
    "        temp_topic = ind\n",
    "        temp_likelihood = round(con_doc_mixes[i][ind], 2)\n",
    "        likelihood_top = -1\n",
    "        topic_top = -1\n",
    "        if temp_likelihood > likelihood_top:\n",
    "            likelihood_top = temp_likelihood\n",
    "            topic_top = temp_topic\n",
    "        my_top+=' '+str(ind)+':'+str(round(con_doc_mixes[i][ind],2))\n",
    "        if i in doc_topic:\n",
    "            doc_topic[i].append((ind, round(con_doc_mixes[i][ind], 2)))\n",
    "        else:\n",
    "            doc_topic[i] = [(ind, round(con_doc_mixes[i][ind], 2))]\n",
    "    doc_top_topic[i] = topic_top\n",
    "    fw.write('DOC: '+str(i)+' --> '+str(my_top)+'\\n')\n",
    "fw.close()\n",
    "\n",
    "#print out top k cons\n",
    "k_user = 2 #user parameter\n",
    "invers_count = {}\n",
    "for key, value in doc_top_topic.items():\n",
    "    if value in invers_count:\n",
    "        invers_count[value] += 1\n",
    "    else:\n",
    "        invers_count[value] = 1\n",
    "\n",
    "count_dic = {}\n",
    "for k,v in invers_count.items():\n",
    "    count_dic[v] = k\n",
    "\n",
    "for i in range(k_user):\n",
    "    l = len(count_dic.keys())\n",
    "    i_topicNum = count_dic[sorted(count_dic.keys())[l-i-1]]                \n",
    "    print(\"TOP \", i+1, \" con comments' keywords are \", topic_keywords[i_topicNum])\n",
    "    \n",
    "    for docj, portion in doc_topic.items():\n",
    "        for j, posb in portion:\n",
    "            if j == i_topicNum and posb > 0.8:\n",
    "                print(\"e.g. \", cons[docj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
